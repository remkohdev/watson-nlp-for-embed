{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Embeddable AI \u00b6 You can access this page via https://ibm.biz/watson-nlp-for-embed . Pre-requisites \u00b6 Open landing page DSCE , Open https://github.com/IBM/dsce-sample-apps/tree/main/entity-extraction , Open http://localhost:8050/ for local demo, Open IBM Watson Natural Language Processing Library for Embed Trial , Open to edit Jupyter Notebook Emotion Classification - Custom Model , Check your reservation of Watson Studio sandbox at https://techzone.ibm.com/collection/watson-nlp-library-hands-on-lab/journey-use-model . Login to https://dataplatform.cloud.ibm.com/home2?context=cpdaas Introduction \u00b6 About Me \u00b6 ... Objective \u00b6 In this demo, I will show how to include advanced AI functionality from IBM Watson in your own applications and use the Watson NLP library for Entities Extraction as an example. In the example I use a pre-trained model but I will also show how to customize a model to increase accuracy for your specific domain using IBM Watson Studio and re-build a custom image of the Watson NLP. I use an online wizard (DSCE) to guide anyone through the steps. Terms Used \u00b6 Some terms used: DSCE is IBM Digital Self-Serve Co-Create Experience (DSCE) , an IBM wizard that makes it easy to try IBM products like IBM Watson libraries. IBM TechZone makes free POC environments or sandboxes of IBM products available to IBM partners. To access TechZone your IBM Id must be registered in your PartnerPlus account. You must have an IBM PartnerPlus account. IBM Build Lab is part of the IBM Ecosystem Engineering organization that helps IBM partners with embedding IBM products in their own product (as part of an ESA agreement) for free. Embedded AI refers to the use of AI directly in your own products or IBM products so that you can run your AI applications anywhere, including disconnected on-prem environments, Azure, or AWS. Other IBM products use embedded AI : Instana, Turbonomic, Watson Assistant, Watson Discovery, Maximo, Maximo Visual Inspection (MVI), etc. Agenda \u00b6 Introduction Start with DSCE wizard, Demo: Use a Pre-Trained Model, Get an Entitlement Key and Sign up for Trial Use Watson Studio for Custom Model in TechZone Conclusion Start with DSCE \u00b6 Go to https://dsce.ibm.com/ to use the DSCE Wizard, Click Get Started , Select \"Find and try AI\", click Start, Click Build with AI libraries , Click Build with Watson NLP , Click Entities extraction , Click Library and container , So now you are familiar with DSCE, let's look at using a pre-trained model in a demo. Demo: Use a Pre-Trained Model \u00b6 In this section, I will continue in DSCE and run sample Python code embedding Watson NLP with the pre-trained model in a demo. Click Use a pre-trained model , Click Next, Review he Try steps: In Step 1, you can review a few use cases: entity extraction can be Voice of the Customer , a technique used to gather and analyze feedback from customers to improve products, services, and the customer experience. Or, extract Personal Identifiable Information (PII) for Compliance or Verification, Skip the live demo application in Step 2, because I am running the demo from the application code sample in Step 3, In step 3, get the code for the Entity Extraction demo app at https://github.com/IBM/dsce-sample-apps/tree/main/entity-extraction , Run the code for the client demo following the instructions in the Github README, Open the UI at http://0.0.0.0:8050 , The demo uses a client that accesses the Watson NLP Runtime, which is packaged as a container image hosted on the IBM Entitled Registry. You will need an entitlement key to access it. The demo uses the Watson NLP Runtime deployed on IBM Code Engine, see the client code: # pre-defined URL for backend SERVER_URL = 'https://8f96122371.dsceapp.buildlab.cloud' # API end-points used REQ_URL = SERVER_URL + '/v1/watson.runtime.nlp.v1/NlpService/EntityMentionsPredict' Now you have seen how you can deploy the Watson NLP Runtime and embed it in your client code. Next, let's look at the required steps to get started using embedded AI in your own solutions. Embed AI in your own Solution \u00b6 In the next section, we will step through the steps to start using the IBM Watson NLP Library for Embed in your own solutions. Get Entitlement Key and Sign up for Trial \u00b6 To deploy your own instance of IBM Watson NLP Library for Embed, you first need an Entitlement Key or license. You can sign up for the trial license that allows you to use Watson NLP for 180 days for free. Click the Deploy tab, Click the Get trail license and access container , Sign up for the trial to link the trial license of IBM Watson NLP Library for Embed to your IBM Id , If you have an IBM Id already, click Log in On the IBM account page, Click Manage Products , which will forward you to https://myibm.ibm.com/dashboard/ , Under Trials , you should see your trial of IBM Watson NLP Library for Embed , Under Cloud Paks & container software , you should see a Container Software & Entitlement Keys tile, Click View Library , You can view existing or create new entitlement keys, All good, we verified that the trial is active and you have an entitlement key. You now could already use the default image for Watson NLP using your entitlement key. The default image will use the pre-trained model and give you out-of-the-box results. But most likely, for a specific use case in a specific domain with specific data, you can increase the accuracy of the Watson NLP algorithms by training a custom model. Training of custom models can be done in environments like Watson Studio. Use Watson Studio in TechZone \u00b6 To train a custom model you can use Watson Studio. IBM TechZone makes free POC environments or sandboxes of IBM products like Watson Studio available to IBM partners. To reserve a Watson Studio environment, follow the instructions in this TechZone Tutorial , Use a Custom Model \u00b6 Reserve a Watson Studio environment in TechZone . Select Reserve now, When filling in the form you can set: Purpose: Practice/Self-Education Purpose description: Hands-on lab Preferred geography: AMERICAS - us-south region - any datacenter Check your Reservations in TechZone , to make sure the Watson Studio sandbox is Ready, If the Environment Status is Ready, continue, Login to https://dataplatform.cloud.ibm.com/home2?context=cpdaas In the top right, you should see an active account 2577353 - tsglwatson , if not, switch the active account, In the Projects tile, you should notice a project named emotion-classification-[hash] , Click the emotion classification project to open it, You should see 3 assets: Emotion Classification - Custom Model , Emotion Classification - Pre-Trained Model , and emotion-tweets.csv , If you don't see all 3 assets, click the View all link in the assets tile or go to the Assets tab, Next, create an asset token, Click on the Manage tab. Switch to the Access control menu item on the left, then select Access tokens , If no token exists yet, click New access token , Enter a Name for the access token, and select Editor in the Access role. Then, click Create. Click on the Assets tab, and find the notebook Emotion Classification - Custom Models . Click the three dots on the right to open a drop-down menu, select Edit, Your notebook will load, Once your notebook has loaded, in the top right of the horizontal tool bar, click the 3 dots dropdown, and select Insert project token, You should see the token been inserted at the top of your notebook, You're all set! You are now ready to customize your model and edit the notebook. After you edited your notebook, you only need to rebuild your container image with the custom model for Watson NLP and redeploy it. Build Custom Model Image \u00b6 Instead of using the pre-trained model, you can also use the customized model and build the container image for deployment with the custom model. Follow the instructions at Build the custom model container . There is a boilerplate code for your custom model container, # Watson Studio project.save_data ( 'ensemble_model' , data = ensemble_model.as_file_like_object () , overwrite = True ) # Dockerfile ARG WATSON_RUNTIME_BASE = \"wcp-ai-foundation-team-docker-virtual.artifactory.swg-devops.com/watson-nlp-runtime:1.0.0\" FROM ${WATSON_RUNTIME_BASE} as base ENV LOCAL_MODELS_DIR = /app/models COPY models /app/models docker build . -t watson-nlp-custom-container:v1 That concludes this demo. Work with IBM Build Lab \u00b6 If you have any questions or want to work on your solution with us 1-on-1, you can contact us via the DSCE site . In the top-right, click Contact Us , To learn more about embeddable AI using Watson NLP see the Assets for Watson NLP by Build Lab at https://github.com/ibm-build-lab/Watson-NLP .","title":"Home"},{"location":"#embeddable-ai","text":"You can access this page via https://ibm.biz/watson-nlp-for-embed .","title":"Embeddable AI"},{"location":"#pre-requisites","text":"Open landing page DSCE , Open https://github.com/IBM/dsce-sample-apps/tree/main/entity-extraction , Open http://localhost:8050/ for local demo, Open IBM Watson Natural Language Processing Library for Embed Trial , Open to edit Jupyter Notebook Emotion Classification - Custom Model , Check your reservation of Watson Studio sandbox at https://techzone.ibm.com/collection/watson-nlp-library-hands-on-lab/journey-use-model . Login to https://dataplatform.cloud.ibm.com/home2?context=cpdaas","title":"Pre-requisites"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#about-me","text":"...","title":"About Me"},{"location":"#objective","text":"In this demo, I will show how to include advanced AI functionality from IBM Watson in your own applications and use the Watson NLP library for Entities Extraction as an example. In the example I use a pre-trained model but I will also show how to customize a model to increase accuracy for your specific domain using IBM Watson Studio and re-build a custom image of the Watson NLP. I use an online wizard (DSCE) to guide anyone through the steps.","title":"Objective"},{"location":"#terms-used","text":"Some terms used: DSCE is IBM Digital Self-Serve Co-Create Experience (DSCE) , an IBM wizard that makes it easy to try IBM products like IBM Watson libraries. IBM TechZone makes free POC environments or sandboxes of IBM products available to IBM partners. To access TechZone your IBM Id must be registered in your PartnerPlus account. You must have an IBM PartnerPlus account. IBM Build Lab is part of the IBM Ecosystem Engineering organization that helps IBM partners with embedding IBM products in their own product (as part of an ESA agreement) for free. Embedded AI refers to the use of AI directly in your own products or IBM products so that you can run your AI applications anywhere, including disconnected on-prem environments, Azure, or AWS. Other IBM products use embedded AI : Instana, Turbonomic, Watson Assistant, Watson Discovery, Maximo, Maximo Visual Inspection (MVI), etc.","title":"Terms Used"},{"location":"#agenda","text":"Introduction Start with DSCE wizard, Demo: Use a Pre-Trained Model, Get an Entitlement Key and Sign up for Trial Use Watson Studio for Custom Model in TechZone Conclusion","title":"Agenda"},{"location":"#start-with-dsce","text":"Go to https://dsce.ibm.com/ to use the DSCE Wizard, Click Get Started , Select \"Find and try AI\", click Start, Click Build with AI libraries , Click Build with Watson NLP , Click Entities extraction , Click Library and container , So now you are familiar with DSCE, let's look at using a pre-trained model in a demo.","title":"Start with DSCE"},{"location":"#demo-use-a-pre-trained-model","text":"In this section, I will continue in DSCE and run sample Python code embedding Watson NLP with the pre-trained model in a demo. Click Use a pre-trained model , Click Next, Review he Try steps: In Step 1, you can review a few use cases: entity extraction can be Voice of the Customer , a technique used to gather and analyze feedback from customers to improve products, services, and the customer experience. Or, extract Personal Identifiable Information (PII) for Compliance or Verification, Skip the live demo application in Step 2, because I am running the demo from the application code sample in Step 3, In step 3, get the code for the Entity Extraction demo app at https://github.com/IBM/dsce-sample-apps/tree/main/entity-extraction , Run the code for the client demo following the instructions in the Github README, Open the UI at http://0.0.0.0:8050 , The demo uses a client that accesses the Watson NLP Runtime, which is packaged as a container image hosted on the IBM Entitled Registry. You will need an entitlement key to access it. The demo uses the Watson NLP Runtime deployed on IBM Code Engine, see the client code: # pre-defined URL for backend SERVER_URL = 'https://8f96122371.dsceapp.buildlab.cloud' # API end-points used REQ_URL = SERVER_URL + '/v1/watson.runtime.nlp.v1/NlpService/EntityMentionsPredict' Now you have seen how you can deploy the Watson NLP Runtime and embed it in your client code. Next, let's look at the required steps to get started using embedded AI in your own solutions.","title":"Demo: Use a Pre-Trained Model"},{"location":"#embed-ai-in-your-own-solution","text":"In the next section, we will step through the steps to start using the IBM Watson NLP Library for Embed in your own solutions.","title":"Embed AI in your own Solution"},{"location":"#get-entitlement-key-and-sign-up-for-trial","text":"To deploy your own instance of IBM Watson NLP Library for Embed, you first need an Entitlement Key or license. You can sign up for the trial license that allows you to use Watson NLP for 180 days for free. Click the Deploy tab, Click the Get trail license and access container , Sign up for the trial to link the trial license of IBM Watson NLP Library for Embed to your IBM Id , If you have an IBM Id already, click Log in On the IBM account page, Click Manage Products , which will forward you to https://myibm.ibm.com/dashboard/ , Under Trials , you should see your trial of IBM Watson NLP Library for Embed , Under Cloud Paks & container software , you should see a Container Software & Entitlement Keys tile, Click View Library , You can view existing or create new entitlement keys, All good, we verified that the trial is active and you have an entitlement key. You now could already use the default image for Watson NLP using your entitlement key. The default image will use the pre-trained model and give you out-of-the-box results. But most likely, for a specific use case in a specific domain with specific data, you can increase the accuracy of the Watson NLP algorithms by training a custom model. Training of custom models can be done in environments like Watson Studio.","title":"Get Entitlement Key and Sign up for Trial"},{"location":"#use-watson-studio-in-techzone","text":"To train a custom model you can use Watson Studio. IBM TechZone makes free POC environments or sandboxes of IBM products like Watson Studio available to IBM partners. To reserve a Watson Studio environment, follow the instructions in this TechZone Tutorial ,","title":"Use Watson Studio in TechZone"},{"location":"#use-a-custom-model","text":"Reserve a Watson Studio environment in TechZone . Select Reserve now, When filling in the form you can set: Purpose: Practice/Self-Education Purpose description: Hands-on lab Preferred geography: AMERICAS - us-south region - any datacenter Check your Reservations in TechZone , to make sure the Watson Studio sandbox is Ready, If the Environment Status is Ready, continue, Login to https://dataplatform.cloud.ibm.com/home2?context=cpdaas In the top right, you should see an active account 2577353 - tsglwatson , if not, switch the active account, In the Projects tile, you should notice a project named emotion-classification-[hash] , Click the emotion classification project to open it, You should see 3 assets: Emotion Classification - Custom Model , Emotion Classification - Pre-Trained Model , and emotion-tweets.csv , If you don't see all 3 assets, click the View all link in the assets tile or go to the Assets tab, Next, create an asset token, Click on the Manage tab. Switch to the Access control menu item on the left, then select Access tokens , If no token exists yet, click New access token , Enter a Name for the access token, and select Editor in the Access role. Then, click Create. Click on the Assets tab, and find the notebook Emotion Classification - Custom Models . Click the three dots on the right to open a drop-down menu, select Edit, Your notebook will load, Once your notebook has loaded, in the top right of the horizontal tool bar, click the 3 dots dropdown, and select Insert project token, You should see the token been inserted at the top of your notebook, You're all set! You are now ready to customize your model and edit the notebook. After you edited your notebook, you only need to rebuild your container image with the custom model for Watson NLP and redeploy it.","title":"Use a Custom Model"},{"location":"#build-custom-model-image","text":"Instead of using the pre-trained model, you can also use the customized model and build the container image for deployment with the custom model. Follow the instructions at Build the custom model container . There is a boilerplate code for your custom model container, # Watson Studio project.save_data ( 'ensemble_model' , data = ensemble_model.as_file_like_object () , overwrite = True ) # Dockerfile ARG WATSON_RUNTIME_BASE = \"wcp-ai-foundation-team-docker-virtual.artifactory.swg-devops.com/watson-nlp-runtime:1.0.0\" FROM ${WATSON_RUNTIME_BASE} as base ENV LOCAL_MODELS_DIR = /app/models COPY models /app/models docker build . -t watson-nlp-custom-container:v1 That concludes this demo.","title":"Build Custom Model Image"},{"location":"#work-with-ibm-build-lab","text":"If you have any questions or want to work on your solution with us 1-on-1, you can contact us via the DSCE site . In the top-right, click Contact Us , To learn more about embeddable AI using Watson NLP see the Assets for Watson NLP by Build Lab at https://github.com/ibm-build-lab/Watson-NLP .","title":"Work with IBM Build Lab"},{"location":"references/CONTRIBUTORS/","text":"Contributors \u00b6 Remko de Knikker, github , Steve Martinelli, github , John Zaccone, github ,","title":"Contributors"},{"location":"references/CONTRIBUTORS/#contributors","text":"Remko de Knikker, github , Steve Martinelli, github , John Zaccone, github ,","title":"Contributors"},{"location":"references/RESOURCES/","text":"Additional resources \u00b6 IBM Demos \u00b6 Collection: InfoSphere Information Server Tutorial: Transforming your data with IBM DataStage Redbooks \u00b6 IBM InfoSphere DataStage Data Flow and Job Design InfoSphere DataStage Parallel Framework Standard Practices Videos \u00b6 Video: Postal codes and part numbers (DataStage) Video: Calculate employee compensation (read from CSV) (DataStage and Gov. Catalog) Video: Banks have merged (DataStage and Gov. Catalog) Video: Groceries with Kafka (DataStage) Video: Find relationships between sales, employees, and customers (Information Analyzer) Video: Clean and analyze data (Governance Catalog)","title":"Additional resources"},{"location":"references/RESOURCES/#additional-resources","text":"","title":"Additional resources"},{"location":"references/RESOURCES/#ibm-demos","text":"Collection: InfoSphere Information Server Tutorial: Transforming your data with IBM DataStage","title":"IBM Demos"},{"location":"references/RESOURCES/#redbooks","text":"IBM InfoSphere DataStage Data Flow and Job Design InfoSphere DataStage Parallel Framework Standard Practices","title":"Redbooks"},{"location":"references/RESOURCES/#videos","text":"Video: Postal codes and part numbers (DataStage) Video: Calculate employee compensation (read from CSV) (DataStage and Gov. Catalog) Video: Banks have merged (DataStage and Gov. Catalog) Video: Groceries with Kafka (DataStage) Video: Find relationships between sales, employees, and customers (Information Analyzer) Video: Clean and analyze data (Governance Catalog)","title":"Videos"}]}